{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Extraneous-comment-management-ECM-in-e-learning/blob/main/Model_Training_Saad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HLNoZfkBUGc"
      },
      "source": [
        "# **1-Import library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkuJaCW9bT6u"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import json\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbN0QbsScujH",
        "outputId": "dd2f819d-e64b-48bc-ffa5-33971b5df5b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "slixlMlwdJji",
        "outputId": "b4226f66-9453-4a98-f98c-eae2ad7f0f91"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.13.0'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpC21eawvwSY"
      },
      "source": [
        "#**2-Dataset Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R60NmwbGDNp2",
        "outputId": "4d4348b0-57bd-41f6-ad55-d36759367c84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfFYn2f_b5u9",
        "outputId": "1805bcc3-70ef-47fb-e5f1-72ec8deb7288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing the intents..........\n"
          ]
        }
      ],
      "source": [
        "words=[]\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?', '!',\"'\",]\n",
        "print(\"Processing the intents..........\")\n",
        "path_to_save_model =\"/content/gdrive/MyDrive/TrainedModel/\"\n",
        "with open('/content/gdrive/MyDrive/Proposal/Dataset/intentsnew (6).json') as json_data:\n",
        "  intents = json.load(json_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yl5GZnxZnI3"
      },
      "source": [
        "# **3-Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICA7KJTRD768",
        "outputId": "29cc8851-bc73-43f7-c47d-d9b81f940d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looping through intents to convert them to words, classes, documents and ignore_words.........\n"
          ]
        }
      ],
      "source": [
        "print(\"Looping through intents to convert them to words, classes, documents and ignore_words.........\")\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        #tokenize each word in the sentence\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        #add to our words list\n",
        "        words.extend(w)\n",
        "        # add to documents in the corpus\n",
        "        documents.append((w, intent['tag']))\n",
        "        # add to our classes list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-azsX0L8c7hX",
        "outputId": "4109b00d-3446-464c-c9d8-b403320ffe96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "305 documents\n",
            "113 classes ['BCPLstand', 'C++', 'Campus changed', 'CandC++', 'Credit', 'Dev C++', 'IDE', 'Introduction C Programming', 'Introduction to  C/C+ Programming', 'LecCS201CS201P', 'OOP', 'Practical', 'Result', 'VSIDE', 'about', 'academic_support', 'addordropcourses', 'admission', 'admission_criteria', 'admission_process', 'admission_types', 'appearforexam', 'askquestionfromteacher', 'assignments', 'avoid_plagiarism', 'benefits', 'bestprogramlanguage', 'campuschange', 'career_services', 'cgpa', 'comparablecourses', 'complaint', 'concerncertificate', 'contact_professor', 'contactadmissiondepartment', 'continueeducationaftercompletingdefree', 'course selection', 'coursesyllabus', 'create account', 'datasavedisk', 'defragmentation', 'downloaddev', 'duplicateid', 'exam_system', 'exam_type', 'expensiveeducation', 'faculty_contact', 'fee_deadline', 'fee_installments', 'fee_structure', 'finalterm', 'financial_aid', 'fragmentation', 'freezeaccount', 'functions', 'functions type', 'functon declaration', 'gdIDE', 'gdb', 'goodbye', 'gpa', 'grading_scheme', 'greetings', 'help', 'historycinfluencelanguage', 'historyprogramlanguage', 'how_to_study', 'howtostudy', 'importanceprogram', 'improvecod', 'institution', 'language', 'lecturehandoutsanddvd', 'lecwat', 'library', 'logicop', 'midterm', 'migrationcertificate', 'mistakeexpression', 'name', 'online_learning', 'operatecomputer', 'passing_criteria', 'payment_options', 'physical session', 'physical_campus', 'plagiarism', 'plagiarism_consequences', 'professor_feedback', 'professors', 'programmingtough', 'quizzes', 'recognizeddegree', 'social', 'standardsofeducation', 'student status Overseas to Pakistan and Vice Versa', 'student_support', 'studentstatusupdation', 'study_tips', 'support_services', 'support_system', 'technical_support', 'term', 'thanks', 'time_management', 'twaindrivers', 'uniformeducation', 'virtual_campus', 'vu_campuses', 'vu_cost', 'vu_professors', 'wheretostudy', 'writeprogram']\n",
            "391 unique lemmatized words ['&', \"''\", \"'m\", \"'s\", '(', ')', ',', '10', '``', 'a', 'able', 'about', 'academic', 'account', 'activity', 'add', 'admission', 'advantage', 'after', 'aid', 'algorithm', 'all', 'am', 'an', 'and', 'any', 'appear', 'apply', 'appreciate', 'are', 'ask', 'assignment', 'assistance', 'at', 'attend', 'attending', 'available', 'avoid', 'avoiding', 'basic', 'bcpl', 'be', 'benefit', 'best', 'better', 'between', 'both', 'but', 'by', 'bye', 'c', 'c++', 'calculated', 'call', 'campus', 'can', 'card', 'career', 'caught', 'certificate', 'certificate/no', 'cgpa', 'change', 'changed', 'choose', 'class', 'code', 'coding', 'common', 'comparable', 'complaint', 'completing', 'computer', 'concern', 'conducted', 'consequence', 'contact', 'content', 'contents/syllabus', 'continue', 'cost', 'could', 'country', 'course', 'cpp', 'create', 'credit', 'criterion', 'cs201', 'cs201p', 'daily', 'data', 'deadline', 'deal', 'declaration', 'declare', 'decleration', 'define', 'defragmentation', 'degree', 'department', 'depth', 'dev', 'develop', 'developed', 'development', 'difference', 'different', 'differentiate', 'discoverer', 'disk', 'do', 'doe', 'dowload', 'download', 'driver', 'drop', 'duplicate', 'duration', 'dvd', 'dy', 'editor', 'education', 'effective', 'effectively', 'evening', 'exam', 'expensive', 'explain', 'expression', 'facility', 'faculty', 'fee', 'feedback', 'final', 'financial', 'first', 'for', 'fragmentation', 'freeze', 'freeze/unfreeze', 'from', 'function', 'gdb', 'get', 'give', 'go', 'goal', 'good', 'goodbye', 'government', 'gpa', 'grade', 'grading', 'group', 'guidlines', 'hand', 'handout', 'happens', 'have', 'held', 'hello', 'help', 'hey', 'hi', 'highly', 'history', 'hour', 'how', 'i', 'id', 'ide', 'idea', 'ideal', 'ides', 'if', 'importance', 'important', 'improve', 'in', 'influence', 'installment', 'institution', 'instructor', 'interesting', 'international', 'inventer', 'is', 'issue', 'it', 'k', 'karien', 'keise', 'ki', 'kind', 'know', 'language', 'later', 'latest', 'learn', 'learning', 'lectuer', 'lecture', 'library', 'life', 'link', 'list', 'liye', 'located', 'logical', 'look', 'manage', 'management', 'many', 'mark', 'may', 'me', 'mean', 'midterm', 'migration', 'minimum', 'mistake', 'morning', 'much', 'must', 'my', \"n't\", 'name', 'necessary', 'need', 'new', 'noc', 'not', 'objection', 'obtain', 'obtaining', 'of', 'offer', 'offered', 'on', 'one', 'online', 'oop', 'open', 'operate', 'operator', 'option', 'or', 'other', 'our', 'out', 'over', 'overseas', 'pakistan', 'pakistani', 'paper', 'passing', 'pay', 'paying', 'payment', 'performance', 'physical', 'pitfall', 'plagiarism', 'plagiarizing', 'platform', 'playable', 'please', 'plus', 'policy', 'possible', 'practical', 'preferable', 'private', 'pro', 'procedure', 'process', 'professor', 'program', 'programming', 'protocol', 'provide', 'province', 'purpose', 'quality', 'question', 'quiz', 'raise', 'reach', 'really', 'recheching', 'recipie', 'recognized', 'recommended', 'required', 'requirement', 's', 'same', 'saved', 'scheme', 'see', 'select', 'selection', 'selection/to', 'semester', 'service', 'session', 'should', 'significance', 'sir', 'skill', 'software', 'some', 'stand', 'standard', 'status', 'still', 'stored', 'structure', 'struggling', 'student', 'study', 'study/degree', 'studying', 'submission', 'support', 'syllabus', 'system', 'taking', 'taught', 'teacher', 'technical', 'technique', 'technologo', 'tell', 'term', 'thank', 'thanks', 'the', 'there', 'thing', 'this', 'through', 'time', 'tip', 'to', 'touch', 'tough', 'traditional', 'tuition', 'twain', 'type', 'unfreeze', 'uniform', 'university', 'unplayable', 'use', 'used', 'v', 'various', 'version', 'very', 'virtual', 'visit', 'vu', 'wa', 'want', 'watch', 'way', 'we', 'weightage', 'what', 'whats', 'whatsapp', 'whay', 'when', 'where', 'which', 'who', 'whom', 'why', 'will', 'window', 'with', 'without', 'work', 'working', 'writing', 'year', 'you', 'your']\n"
          ]
        }
      ],
      "source": [
        "# lemmaztize and lower each word and remove duplicates\n",
        "nltk.download('wordnet')\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(list(set(words)))\n",
        "# sort classes\n",
        "classes = sorted(list(set(classes)))\n",
        "# documents = combination between patterns and intents\n",
        "print (len(documents), \"documents\")\n",
        "# classes = intents\n",
        "print (len(classes), \"classes\", classes)\n",
        "# words = all words, vocabulary\n",
        "print (len(words), \"unique lemmatized words\", words)\n",
        "pickle.dump(words,open('texts.pkl','wb'))\n",
        "pickle.dump(classes,open('labels.pkl','wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZDzp9HIMs30",
        "outputId": "416ba300-fb01-4af4-b391-b45d79f5464e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating the Data for Our Model......\n",
            "Creating an List (Empty) for Output.....\n",
            "Creating Training Set, Bag of Words for our Model.....\n",
            "Training data created\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating the Data for Our Model......\")\n",
        "training = []\n",
        "output = []\n",
        "print(\"Creating an List (Empty) for Output.....\")\n",
        "output_empty = [0] * len(classes)\n",
        "print(\"Creating Training Set, Bag of Words for our Model.....\")\n",
        "\n",
        "for document in documents:\n",
        "  #initialize our bag of words\n",
        "  bag = []\n",
        "  #list of tokenized words for the pattern\n",
        "  pattern_words = document[0]\n",
        "  #lemmatize each word - create base word, in attempt to represent related words\n",
        "  pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "  #create our bag of words array with 1, if word match found in current pattern\n",
        "  for word in words:\n",
        "    bag.append(1) if word in pattern_words else bag.append(0)\n",
        "\n",
        "    #output is a '0' for each tag and '1' for current tag (for each pattern)\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(document[1])] = 1\n",
        "\n",
        "    training.append([bag, output_row])\n",
        "\n",
        "#shuffle our features into np.array\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "\n",
        "#create train and test lists. X - patterns, Y - intents\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n",
        "\n",
        "print(\"Training data created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiA5mfO_bf5G"
      },
      "source": [
        "# **4-Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-gDV4j8l0L0"
      },
      "source": [
        "## **4.1-Neural Netowrk**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em4aCw6ImU3R"
      },
      "source": [
        "### **4.1.1 Model Saving**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "GwFda9VsmgQC",
        "outputId": "8d144a90-5205-48d3-c76c-95b0ea823a95"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-73dfaa568609>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chat_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model created\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.save('chat_model_1', hist)\n",
        "print(\"model created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HvFngP6nzWA"
      },
      "source": [
        "## **4.2- LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nVA9smHqt4v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Flatten,Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLxnK1_RLO4a"
      },
      "source": [
        "### **4.2.1 - Model Architecture 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcFSuMKmq2C_",
        "outputId": "7671f498-a230-42bc-eba7-bf60c327510c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 391, 64)           16896     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 391, 64)           0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 391, 64)           256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 391, 32)           12416     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 391, 32)           0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 391, 32)           128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 16)                3136      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 16)                64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 113)               1921      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34817 (136.00 KB)\n",
            "Trainable params: 34593 (135.13 KB)\n",
            "Non-trainable params: 224 (896.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "932/932 [==============================] - 49s 41ms/step - loss: 3.6133 - accuracy: 0.1375\n",
            "Epoch 2/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 2.4981 - accuracy: 0.2849\n",
            "Epoch 3/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 1.9345 - accuracy: 0.4073\n",
            "Epoch 4/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 1.5499 - accuracy: 0.5017\n",
            "Epoch 5/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 1.1874 - accuracy: 0.5978\n",
            "Epoch 6/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 1.1353 - accuracy: 0.6255\n",
            "Epoch 7/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.7881 - accuracy: 0.7178\n",
            "Epoch 8/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.6873 - accuracy: 0.7552\n",
            "Epoch 9/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.5629 - accuracy: 0.7968\n",
            "Epoch 10/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.4882 - accuracy: 0.8261\n",
            "Epoch 11/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.4232 - accuracy: 0.8552\n",
            "Epoch 12/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 2.3920 - accuracy: 0.4439\n",
            "Epoch 13/200\n",
            "932/932 [==============================] - 39s 41ms/step - loss: 1.8861 - accuracy: 0.4127\n",
            "Epoch 14/200\n",
            "932/932 [==============================] - 39s 42ms/step - loss: 1.3765 - accuracy: 0.5476\n",
            "Epoch 15/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 1.0874 - accuracy: 0.6319\n",
            "Epoch 16/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.9156 - accuracy: 0.6882\n",
            "Epoch 17/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 1.1648 - accuracy: 0.6425\n",
            "Epoch 18/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 1.0362 - accuracy: 0.6492\n",
            "Epoch 19/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.7393 - accuracy: 0.7406\n",
            "Epoch 20/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.8776 - accuracy: 0.7214\n",
            "Epoch 21/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.5864 - accuracy: 0.7926\n",
            "Epoch 22/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.5474 - accuracy: 0.8072\n",
            "Epoch 23/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.5203 - accuracy: 0.8185\n",
            "Epoch 24/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.4806 - accuracy: 0.8323\n",
            "Epoch 25/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.6008 - accuracy: 0.8092\n",
            "Epoch 26/200\n",
            "932/932 [==============================] - 39s 41ms/step - loss: 0.7126 - accuracy: 0.7743\n",
            "Epoch 27/200\n",
            "932/932 [==============================] - 39s 42ms/step - loss: 0.4306 - accuracy: 0.8489\n",
            "Epoch 28/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.4311 - accuracy: 0.8515\n",
            "Epoch 29/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.4064 - accuracy: 0.8599\n",
            "Epoch 30/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.3933 - accuracy: 0.8637\n",
            "Epoch 31/200\n",
            "932/932 [==============================] - 39s 41ms/step - loss: 0.3126 - accuracy: 0.8887\n",
            "Epoch 32/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 2.0606 - accuracy: 0.4725\n",
            "Epoch 33/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.8982 - accuracy: 0.6899\n",
            "Epoch 34/200\n",
            "932/932 [==============================] - 39s 41ms/step - loss: 0.6141 - accuracy: 0.7837\n",
            "Epoch 35/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.4880 - accuracy: 0.8272\n",
            "Epoch 36/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.4088 - accuracy: 0.8554\n",
            "Epoch 37/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.3837 - accuracy: 0.8655\n",
            "Epoch 38/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.3362 - accuracy: 0.8812\n",
            "Epoch 39/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.3194 - accuracy: 0.8896\n",
            "Epoch 40/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2807 - accuracy: 0.9008\n",
            "Epoch 41/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2824 - accuracy: 0.9024\n",
            "Epoch 42/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.2356 - accuracy: 0.9175\n",
            "Epoch 43/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2694 - accuracy: 0.9083\n",
            "Epoch 44/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2286 - accuracy: 0.9212\n",
            "Epoch 45/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2229 - accuracy: 0.9227\n",
            "Epoch 46/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2133 - accuracy: 0.9260\n",
            "Epoch 47/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.2241 - accuracy: 0.9234\n",
            "Epoch 48/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2012 - accuracy: 0.9307\n",
            "Epoch 49/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.2034 - accuracy: 0.9303\n",
            "Epoch 50/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.2255 - accuracy: 0.9242\n",
            "Epoch 51/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.2669 - accuracy: 0.9148\n",
            "Epoch 52/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.1744 - accuracy: 0.9404\n",
            "Epoch 53/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1838 - accuracy: 0.9378\n",
            "Epoch 54/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.1774 - accuracy: 0.9397\n",
            "Epoch 55/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1787 - accuracy: 0.9394\n",
            "Epoch 56/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.2307 - accuracy: 0.9284\n",
            "Epoch 57/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2733 - accuracy: 0.9200\n",
            "Epoch 58/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.1676 - accuracy: 0.9424\n",
            "Epoch 59/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1477 - accuracy: 0.9496\n",
            "Epoch 60/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.1620 - accuracy: 0.9444\n",
            "Epoch 61/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1439 - accuracy: 0.9515\n",
            "Epoch 62/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.1442 - accuracy: 0.9506\n",
            "Epoch 63/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.1382 - accuracy: 0.9526\n",
            "Epoch 64/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.1837 - accuracy: 0.9394\n",
            "Epoch 65/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1334 - accuracy: 0.9544\n",
            "Epoch 66/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.1310 - accuracy: 0.9547\n",
            "Epoch 67/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.1490 - accuracy: 0.9497\n",
            "Epoch 68/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.1534 - accuracy: 0.9485\n",
            "Epoch 69/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1773 - accuracy: 0.9438\n",
            "Epoch 70/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 1.6260 - accuracy: 0.7683\n",
            "Epoch 71/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 4.6732 - accuracy: 0.0244\n",
            "Epoch 72/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 4.4343 - accuracy: 0.0443\n",
            "Epoch 73/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 4.1243 - accuracy: 0.0687\n",
            "Epoch 74/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 3.9007 - accuracy: 0.0882\n",
            "Epoch 75/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 3.6432 - accuracy: 0.1147\n",
            "Epoch 76/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 3.4595 - accuracy: 0.1356\n",
            "Epoch 77/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 3.3043 - accuracy: 0.1581\n",
            "Epoch 78/200\n",
            "932/932 [==============================] - 37s 39ms/step - loss: 3.1611 - accuracy: 0.1740\n",
            "Epoch 79/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 3.0292 - accuracy: 0.1978\n",
            "Epoch 80/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 2.8187 - accuracy: 0.2346\n",
            "Epoch 81/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 2.5117 - accuracy: 0.2914\n",
            "Epoch 82/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 2.2793 - accuracy: 0.3345\n",
            "Epoch 83/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 2.1087 - accuracy: 0.3686\n",
            "Epoch 84/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 1.9493 - accuracy: 0.4058\n",
            "Epoch 85/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 1.7936 - accuracy: 0.4448\n",
            "Epoch 86/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 1.6609 - accuracy: 0.4821\n",
            "Epoch 87/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 1.5424 - accuracy: 0.5165\n",
            "Epoch 88/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 1.3935 - accuracy: 0.5572\n",
            "Epoch 89/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 1.2978 - accuracy: 0.5893\n",
            "Epoch 90/200\n",
            "932/932 [==============================] - 37s 39ms/step - loss: 1.5018 - accuracy: 0.5386\n",
            "Epoch 91/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 1.2416 - accuracy: 0.6048\n",
            "Epoch 92/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 1.0899 - accuracy: 0.6488\n",
            "Epoch 93/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 1.0067 - accuracy: 0.6782\n",
            "Epoch 94/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.9474 - accuracy: 0.6988\n",
            "Epoch 95/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.8892 - accuracy: 0.7175\n",
            "Epoch 96/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.8004 - accuracy: 0.7464\n",
            "Epoch 97/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.7754 - accuracy: 0.7553\n",
            "Epoch 98/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.7164 - accuracy: 0.7720\n",
            "Epoch 99/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.6660 - accuracy: 0.7904\n",
            "Epoch 100/200\n",
            "932/932 [==============================] - 39s 42ms/step - loss: 0.6750 - accuracy: 0.7892\n",
            "Epoch 101/200\n",
            "932/932 [==============================] - 39s 42ms/step - loss: 0.5637 - accuracy: 0.8197\n",
            "Epoch 102/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.5977 - accuracy: 0.8129\n",
            "Epoch 103/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.7957 - accuracy: 0.7712\n",
            "Epoch 104/200\n",
            "932/932 [==============================] - 39s 41ms/step - loss: 0.5464 - accuracy: 0.8292\n",
            "Epoch 105/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.4903 - accuracy: 0.8455\n",
            "Epoch 106/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.5269 - accuracy: 0.8362\n",
            "Epoch 107/200\n",
            "932/932 [==============================] - 37s 39ms/step - loss: 0.4389 - accuracy: 0.8602\n",
            "Epoch 108/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.4172 - accuracy: 0.8651\n",
            "Epoch 109/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.4028 - accuracy: 0.8713\n",
            "Epoch 110/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.4273 - accuracy: 0.8665\n",
            "Epoch 111/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.4535 - accuracy: 0.8586\n",
            "Epoch 112/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.4031 - accuracy: 0.8741\n",
            "Epoch 113/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.3437 - accuracy: 0.8894\n",
            "Epoch 114/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.3608 - accuracy: 0.8857\n",
            "Epoch 115/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.3334 - accuracy: 0.8918\n",
            "Epoch 116/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.3552 - accuracy: 0.8875\n",
            "Epoch 117/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.3129 - accuracy: 0.8991\n",
            "Epoch 118/200\n",
            "932/932 [==============================] - 39s 42ms/step - loss: 0.3003 - accuracy: 0.9026\n",
            "Epoch 119/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.3990 - accuracy: 0.8845\n",
            "Epoch 120/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.3466 - accuracy: 0.8927\n",
            "Epoch 121/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.2740 - accuracy: 0.9115\n",
            "Epoch 122/200\n",
            "932/932 [==============================] - 39s 42ms/step - loss: 0.2798 - accuracy: 0.9106\n",
            "Epoch 123/200\n",
            "932/932 [==============================] - 39s 42ms/step - loss: 0.2617 - accuracy: 0.9144\n",
            "Epoch 124/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.2501 - accuracy: 0.9190\n",
            "Epoch 125/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.3111 - accuracy: 0.9061\n",
            "Epoch 126/200\n",
            "932/932 [==============================] - 39s 42ms/step - loss: 0.3025 - accuracy: 0.9070\n",
            "Epoch 127/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.2430 - accuracy: 0.9216\n",
            "Epoch 128/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.2403 - accuracy: 0.9225\n",
            "Epoch 129/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2297 - accuracy: 0.9261\n",
            "Epoch 130/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.3098 - accuracy: 0.9105\n",
            "Epoch 131/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.2084 - accuracy: 0.9318\n",
            "Epoch 132/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.1983 - accuracy: 0.9352\n",
            "Epoch 133/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2040 - accuracy: 0.9333\n",
            "Epoch 134/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.3897 - accuracy: 0.8952\n",
            "Epoch 135/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.1907 - accuracy: 0.9378\n",
            "Epoch 136/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1864 - accuracy: 0.9388\n",
            "Epoch 137/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2677 - accuracy: 0.9200\n",
            "Epoch 138/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.1872 - accuracy: 0.9390\n",
            "Epoch 139/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.1743 - accuracy: 0.9427\n",
            "Epoch 140/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.1673 - accuracy: 0.9455\n",
            "Epoch 141/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.1625 - accuracy: 0.9461\n",
            "Epoch 142/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.3662 - accuracy: 0.9071\n",
            "Epoch 143/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.1691 - accuracy: 0.9444\n",
            "Epoch 144/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.1705 - accuracy: 0.9439\n",
            "Epoch 145/200\n",
            "932/932 [==============================] - 37s 39ms/step - loss: 0.1779 - accuracy: 0.9436\n",
            "Epoch 146/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2351 - accuracy: 0.9292\n",
            "Epoch 147/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.1897 - accuracy: 0.9388\n",
            "Epoch 148/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1553 - accuracy: 0.9491\n",
            "Epoch 149/200\n",
            "932/932 [==============================] - 36s 39ms/step - loss: 0.1564 - accuracy: 0.9488\n",
            "Epoch 150/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.2283 - accuracy: 0.9314\n",
            "Epoch 151/200\n",
            "932/932 [==============================] - 38s 41ms/step - loss: 0.1565 - accuracy: 0.9491\n",
            "Epoch 152/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1480 - accuracy: 0.9511\n",
            "Epoch 153/200\n",
            "932/932 [==============================] - 39s 42ms/step - loss: 0.2236 - accuracy: 0.9349\n",
            "Epoch 154/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.1521 - accuracy: 0.9505\n",
            "Epoch 155/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.2160 - accuracy: 0.9378\n",
            "Epoch 156/200\n",
            "932/932 [==============================] - 37s 39ms/step - loss: 0.1412 - accuracy: 0.9535\n",
            "Epoch 157/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1336 - accuracy: 0.9558\n",
            "Epoch 158/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1423 - accuracy: 0.9534\n",
            "Epoch 159/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1332 - accuracy: 0.9553\n",
            "Epoch 160/200\n",
            "932/932 [==============================] - 36s 39ms/step - loss: 0.2427 - accuracy: 0.9344\n",
            "Epoch 161/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1265 - accuracy: 0.9580\n",
            "Epoch 162/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1385 - accuracy: 0.9560\n",
            "Epoch 163/200\n",
            "932/932 [==============================] - 36s 39ms/step - loss: 0.1340 - accuracy: 0.9558\n",
            "Epoch 164/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1252 - accuracy: 0.9582\n",
            "Epoch 165/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1277 - accuracy: 0.9578\n",
            "Epoch 166/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1224 - accuracy: 0.9593\n",
            "Epoch 167/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1291 - accuracy: 0.9576\n",
            "Epoch 168/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.1216 - accuracy: 0.9591\n",
            "Epoch 169/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1240 - accuracy: 0.9597\n",
            "Epoch 170/200\n",
            "932/932 [==============================] - 36s 39ms/step - loss: 0.1153 - accuracy: 0.9615\n",
            "Epoch 171/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2025 - accuracy: 0.9415\n",
            "Epoch 172/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.1131 - accuracy: 0.9626\n",
            "Epoch 173/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1096 - accuracy: 0.9631\n",
            "Epoch 174/200\n",
            "932/932 [==============================] - 37s 39ms/step - loss: 0.1125 - accuracy: 0.9627\n",
            "Epoch 175/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.2381 - accuracy: 0.9325\n",
            "Epoch 176/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1541 - accuracy: 0.9533\n",
            "Epoch 177/200\n",
            "932/932 [==============================] - 36s 39ms/step - loss: 0.1098 - accuracy: 0.9635\n",
            "Epoch 178/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1123 - accuracy: 0.9624\n",
            "Epoch 179/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1021 - accuracy: 0.9657\n",
            "Epoch 180/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1149 - accuracy: 0.9630\n",
            "Epoch 181/200\n",
            "932/932 [==============================] - 37s 39ms/step - loss: 0.1034 - accuracy: 0.9655\n",
            "Epoch 182/200\n",
            "932/932 [==============================] - 38s 40ms/step - loss: 0.1698 - accuracy: 0.9533\n",
            "Epoch 183/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1677 - accuracy: 0.9506\n",
            "Epoch 184/200\n",
            "932/932 [==============================] - 36s 39ms/step - loss: 0.1123 - accuracy: 0.9634\n",
            "Epoch 185/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.3216 - accuracy: 0.9248\n",
            "Epoch 186/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1308 - accuracy: 0.9572\n",
            "Epoch 187/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1171 - accuracy: 0.9619\n",
            "Epoch 188/200\n",
            "932/932 [==============================] - 37s 39ms/step - loss: 0.1006 - accuracy: 0.9664\n",
            "Epoch 189/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.0939 - accuracy: 0.9692\n",
            "Epoch 190/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.0973 - accuracy: 0.9683\n",
            "Epoch 191/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.0996 - accuracy: 0.9668\n",
            "Epoch 192/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.0912 - accuracy: 0.9696\n",
            "Epoch 193/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1102 - accuracy: 0.9649\n",
            "Epoch 194/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.1169 - accuracy: 0.9634\n",
            "Epoch 195/200\n",
            "932/932 [==============================] - 36s 39ms/step - loss: 0.0834 - accuracy: 0.9721\n",
            "Epoch 196/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.0915 - accuracy: 0.9696\n",
            "Epoch 197/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.0840 - accuracy: 0.9717\n",
            "Epoch 198/200\n",
            "932/932 [==============================] - 36s 39ms/step - loss: 0.1306 - accuracy: 0.9586\n",
            "Epoch 199/200\n",
            "932/932 [==============================] - 37s 39ms/step - loss: 0.1003 - accuracy: 0.9673\n",
            "Epoch 200/200\n",
            "932/932 [==============================] - 37s 40ms/step - loss: 0.0812 - accuracy: 0.9728\n"
          ]
        }
      ],
      "source": [
        "#Create the LSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(len(train_x[0]),1), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(32,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(16,return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(len(train_y[0]),activation=\"softmax\"))\n",
        "model.summary()\n",
        "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "#adam = Adam(learning_rate=lr_schedule)\n",
        "sgd = SGD(learning_rate=0.01 ,momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "#fitting and saving the model\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=128, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qQz12ssLy1C"
      },
      "source": [
        "### **4.2.2 - Model Architecture 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUkU6STQLw-S",
        "outputId": "cca37508-c9ed-4cd6-de99-37c3d6f31b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 391, 128)          66560     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 391, 128)          0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 391, 64)           49408     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 391, 64)           0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 391, 64)           256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 391, 32)           12416     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 391, 32)           0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 391, 32)           128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 16)                3136      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 16)                64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 113)               1921      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133889 (523.00 KB)\n",
            "Trainable params: 133665 (522.13 KB)\n",
            "Non-trainable params: 224 (896.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "932/932 [==============================] - 74s 65ms/step - loss: 4.5581 - accuracy: 0.0383\n",
            "Epoch 2/100\n",
            "932/932 [==============================] - 60s 65ms/step - loss: 4.1713 - accuracy: 0.0804\n",
            "Epoch 3/100\n",
            "932/932 [==============================] - 60s 65ms/step - loss: 3.8606 - accuracy: 0.1112\n",
            "Epoch 4/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 3.5848 - accuracy: 0.1402\n",
            "Epoch 5/100\n",
            "932/932 [==============================] - 60s 65ms/step - loss: 3.3244 - accuracy: 0.1727\n",
            "Epoch 6/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 3.0648 - accuracy: 0.2091\n",
            "Epoch 7/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 2.8126 - accuracy: 0.2503\n",
            "Epoch 8/100\n",
            "932/932 [==============================] - 60s 65ms/step - loss: 2.5778 - accuracy: 0.2959\n",
            "Epoch 9/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 2.3691 - accuracy: 0.3390\n",
            "Epoch 10/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 2.1946 - accuracy: 0.3766\n",
            "Epoch 11/100\n",
            "932/932 [==============================] - 60s 65ms/step - loss: 2.0436 - accuracy: 0.4100\n",
            "Epoch 12/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 1.9066 - accuracy: 0.4381\n",
            "Epoch 13/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 1.7714 - accuracy: 0.4702\n",
            "Epoch 14/100\n",
            "932/932 [==============================] - 60s 65ms/step - loss: 1.6573 - accuracy: 0.4969\n",
            "Epoch 15/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 1.5487 - accuracy: 0.5222\n",
            "Epoch 16/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 1.4633 - accuracy: 0.5440\n",
            "Epoch 17/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 1.3791 - accuracy: 0.5649\n",
            "Epoch 18/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 1.3058 - accuracy: 0.5831\n",
            "Epoch 19/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 1.2500 - accuracy: 0.5993\n",
            "Epoch 20/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 1.1978 - accuracy: 0.6140\n",
            "Epoch 21/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 1.1476 - accuracy: 0.6270\n",
            "Epoch 22/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 1.1053 - accuracy: 0.6398\n",
            "Epoch 23/100\n",
            "932/932 [==============================] - 60s 65ms/step - loss: 1.0539 - accuracy: 0.6572\n",
            "Epoch 24/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 1.0007 - accuracy: 0.6712\n",
            "Epoch 25/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.9506 - accuracy: 0.6858\n",
            "Epoch 26/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.8948 - accuracy: 0.7020\n",
            "Epoch 27/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.8563 - accuracy: 0.7137\n",
            "Epoch 28/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.8044 - accuracy: 0.7297\n",
            "Epoch 29/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.7589 - accuracy: 0.7424\n",
            "Epoch 30/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.7170 - accuracy: 0.7551\n",
            "Epoch 31/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.6875 - accuracy: 0.7639\n",
            "Epoch 32/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.6603 - accuracy: 0.7741\n",
            "Epoch 33/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.6073 - accuracy: 0.7915\n",
            "Epoch 34/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.5659 - accuracy: 0.8057\n",
            "Epoch 35/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.6011 - accuracy: 0.7981\n",
            "Epoch 36/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.5179 - accuracy: 0.8205\n",
            "Epoch 37/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.4980 - accuracy: 0.8292\n",
            "Epoch 38/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.4457 - accuracy: 0.8473\n",
            "Epoch 39/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.4617 - accuracy: 0.8452\n",
            "Epoch 40/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.3936 - accuracy: 0.8670\n",
            "Epoch 41/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.3909 - accuracy: 0.8679\n",
            "Epoch 42/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.4034 - accuracy: 0.8678\n",
            "Epoch 43/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.3335 - accuracy: 0.8880\n",
            "Epoch 44/100\n",
            "932/932 [==============================] - 62s 66ms/step - loss: 0.5814 - accuracy: 0.8340\n",
            "Epoch 45/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.3660 - accuracy: 0.8764\n",
            "Epoch 46/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.2975 - accuracy: 0.9026\n",
            "Epoch 47/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.3078 - accuracy: 0.9026\n",
            "Epoch 48/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.2302 - accuracy: 0.9287\n",
            "Epoch 49/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.2394 - accuracy: 0.9268\n",
            "Epoch 50/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.1978 - accuracy: 0.9401\n",
            "Epoch 51/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.1907 - accuracy: 0.9419\n",
            "Epoch 52/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.1922 - accuracy: 0.9428\n",
            "Epoch 53/100\n",
            "932/932 [==============================] - 60s 65ms/step - loss: 0.1581 - accuracy: 0.9544\n",
            "Epoch 54/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.1979 - accuracy: 0.9424\n",
            "Epoch 55/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.1646 - accuracy: 0.9520\n",
            "Epoch 56/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.1581 - accuracy: 0.9541\n",
            "Epoch 57/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.1539 - accuracy: 0.9551\n",
            "Epoch 58/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.3186 - accuracy: 0.9161\n",
            "Epoch 59/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.1247 - accuracy: 0.9639\n",
            "Epoch 60/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.1370 - accuracy: 0.9608\n",
            "Epoch 61/100\n",
            "932/932 [==============================] - 60s 65ms/step - loss: 0.1208 - accuracy: 0.9656\n",
            "Epoch 62/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.1107 - accuracy: 0.9679\n",
            "Epoch 63/100\n",
            "932/932 [==============================] - 62s 66ms/step - loss: 0.1003 - accuracy: 0.9710\n",
            "Epoch 64/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.1150 - accuracy: 0.9669\n",
            "Epoch 65/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0971 - accuracy: 0.9718\n",
            "Epoch 66/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.1128 - accuracy: 0.9679\n",
            "Epoch 67/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0868 - accuracy: 0.9747\n",
            "Epoch 68/100\n",
            "932/932 [==============================] - 62s 66ms/step - loss: 0.0943 - accuracy: 0.9726\n",
            "Epoch 69/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0844 - accuracy: 0.9757\n",
            "Epoch 70/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.1311 - accuracy: 0.9628\n",
            "Epoch 71/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.0825 - accuracy: 0.9755\n",
            "Epoch 72/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0786 - accuracy: 0.9768\n",
            "Epoch 73/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0759 - accuracy: 0.9776\n",
            "Epoch 74/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 1.2304 - accuracy: 0.7290\n",
            "Epoch 75/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.1979 - accuracy: 0.9368\n",
            "Epoch 76/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.1205 - accuracy: 0.9648\n",
            "Epoch 77/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0978 - accuracy: 0.9722\n",
            "Epoch 78/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0864 - accuracy: 0.9756\n",
            "Epoch 79/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.1165 - accuracy: 0.9685\n",
            "Epoch 80/100\n",
            "932/932 [==============================] - 60s 65ms/step - loss: 0.0837 - accuracy: 0.9762\n",
            "Epoch 81/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0764 - accuracy: 0.9782\n",
            "Epoch 82/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.0731 - accuracy: 0.9790\n",
            "Epoch 83/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.1561 - accuracy: 0.9605\n",
            "Epoch 84/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.0777 - accuracy: 0.9776\n",
            "Epoch 85/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0720 - accuracy: 0.9793\n",
            "Epoch 86/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.0667 - accuracy: 0.9808\n",
            "Epoch 87/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.0652 - accuracy: 0.9810\n",
            "Epoch 88/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0694 - accuracy: 0.9800\n",
            "Epoch 89/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0655 - accuracy: 0.9807\n",
            "Epoch 90/100\n",
            "932/932 [==============================] - 62s 66ms/step - loss: 0.0578 - accuracy: 0.9832\n",
            "Epoch 91/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0579 - accuracy: 0.9834\n",
            "Epoch 92/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.0619 - accuracy: 0.9817\n",
            "Epoch 93/100\n",
            "932/932 [==============================] - 62s 66ms/step - loss: 0.0569 - accuracy: 0.9832\n",
            "Epoch 94/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.0571 - accuracy: 0.9830\n",
            "Epoch 95/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0546 - accuracy: 0.9834\n",
            "Epoch 96/100\n",
            "932/932 [==============================] - 61s 66ms/step - loss: 0.0576 - accuracy: 0.9827\n",
            "Epoch 97/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0519 - accuracy: 0.9849\n",
            "Epoch 98/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0682 - accuracy: 0.9800\n",
            "Epoch 99/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0513 - accuracy: 0.9848\n",
            "Epoch 100/100\n",
            "932/932 [==============================] - 61s 65ms/step - loss: 0.0506 - accuracy: 0.9848\n"
          ]
        }
      ],
      "source": [
        "#Create the LSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(len(train_x[0]),1), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(32,return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(16,return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(len(train_y[0]),activation=\"softmax\"))\n",
        "model.summary()\n",
        "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "#adam = Adam(learning_rate=lr_schedule)\n",
        "sgd = SGD(learning_rate=0.001 ,momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "#fitting and saving the model\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=100, batch_size=128, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGcC29CeWi4y"
      },
      "source": [
        "### 4.2.2.1 - Model Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueVFk8ZWYS4s",
        "outputId": "d92c59a1-2a4b-4884-93f2-7df4b23eb575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model created and saved\n"
          ]
        }
      ],
      "source": [
        "model.save( path_to_save_model+'chat_model_2', hist)\n",
        "print(\"model created and saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezj7AyRaQ1Kl"
      },
      "source": [
        "### **4.2.3 - Model Architecture 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cJqEH_qWb-8",
        "outputId": "21242e2e-0468-4289-b301-1f70a88fe9ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirection  (None, 391, 128)          33792     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 391, 128)          0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 391, 64)           41216     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 391, 64)           0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 391, 64)           256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 32)                10368     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32)                128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense (Dense)               (None, 113)               3729      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89489 (349.57 KB)\n",
            "Trainable params: 89297 (348.82 KB)\n",
            "Non-trainable params: 192 (768.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(units=64,input_shape=(len(train_x[0]),1),return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(units=32,return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Bidirectional(LSTM(units=16,return_sequences=False)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(len(train_y[0]),activation=\"softmax\"))\n",
        "\n",
        "# Build the model\n",
        "model.build(input_shape=(None, len(train_x[0]), 1))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ZFEBvntTGt",
        "outputId": "f96deecc-a620-4aa9-f7a7-a27bada9adf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "932/932 [==============================] - 89s 80ms/step - loss: 4.5237 - accuracy: 0.0520\n",
            "Epoch 2/100\n",
            "932/932 [==============================] - 73s 79ms/step - loss: 3.7492 - accuracy: 0.1474\n",
            "Epoch 3/100\n",
            "932/932 [==============================] - 74s 79ms/step - loss: 3.2352 - accuracy: 0.2316\n",
            "Epoch 4/100\n",
            "932/932 [==============================] - 73s 79ms/step - loss: 2.7851 - accuracy: 0.3036\n",
            "Epoch 5/100\n",
            "932/932 [==============================] - 73s 79ms/step - loss: 2.4090 - accuracy: 0.3725\n",
            "Epoch 6/100\n",
            "932/932 [==============================] - 73s 78ms/step - loss: 2.0772 - accuracy: 0.4478\n",
            "Epoch 7/100\n",
            "932/932 [==============================] - 74s 79ms/step - loss: 1.7939 - accuracy: 0.5148\n",
            "Epoch 8/100\n",
            "932/932 [==============================] - 74s 80ms/step - loss: 1.5713 - accuracy: 0.5678\n",
            "Epoch 9/100\n",
            "932/932 [==============================] - 74s 80ms/step - loss: 1.3666 - accuracy: 0.6160\n",
            "Epoch 10/100\n",
            "932/932 [==============================] - 74s 80ms/step - loss: 1.2013 - accuracy: 0.6577\n",
            "Epoch 11/100\n",
            "932/932 [==============================] - 74s 79ms/step - loss: 1.1264 - accuracy: 0.6824\n",
            "Epoch 12/100\n",
            "932/932 [==============================] - 74s 79ms/step - loss: 1.2004 - accuracy: 0.6516\n",
            "Epoch 13/100\n",
            "932/932 [==============================] - 74s 79ms/step - loss: 0.8443 - accuracy: 0.7513\n",
            "Epoch 14/100\n",
            "932/932 [==============================] - 73s 78ms/step - loss: 0.7252 - accuracy: 0.7837\n",
            "Epoch 15/100\n",
            "932/932 [==============================] - 73s 78ms/step - loss: 0.8774 - accuracy: 0.7444\n",
            "Epoch 16/100\n",
            "932/932 [==============================] - 73s 78ms/step - loss: 0.6226 - accuracy: 0.8124\n",
            "Epoch 17/100\n",
            "932/932 [==============================] - 74s 79ms/step - loss: 0.5666 - accuracy: 0.8262\n",
            "Epoch 18/100\n",
            "932/932 [==============================] - 73s 78ms/step - loss: 0.5038 - accuracy: 0.8444\n",
            "Epoch 19/100\n",
            "932/932 [==============================] - 73s 79ms/step - loss: 0.4577 - accuracy: 0.8591\n",
            "Epoch 20/100\n",
            "932/932 [==============================] - 73s 79ms/step - loss: 0.4877 - accuracy: 0.8506\n",
            "Epoch 21/100\n",
            "932/932 [==============================] - 74s 79ms/step - loss: 0.3760 - accuracy: 0.8852\n",
            "Epoch 22/100\n",
            "932/932 [==============================] - 73s 79ms/step - loss: 0.7034 - accuracy: 0.8027\n",
            "Epoch 23/100\n",
            "932/932 [==============================] - 73s 78ms/step - loss: 0.4057 - accuracy: 0.8716\n",
            "Epoch 24/100\n",
            "932/932 [==============================] - 74s 79ms/step - loss: 0.3222 - accuracy: 0.9016\n",
            "Epoch 25/100\n",
            "932/932 [==============================] - 74s 79ms/step - loss: 0.2788 - accuracy: 0.9162\n",
            "Epoch 26/100\n",
            "932/932 [==============================] - 74s 80ms/step - loss: 0.2577 - accuracy: 0.9236\n",
            "Epoch 27/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.2141 - accuracy: 0.9397\n",
            "Epoch 28/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.1942 - accuracy: 0.9459\n",
            "Epoch 29/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.1748 - accuracy: 0.9508\n",
            "Epoch 30/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.1582 - accuracy: 0.9571\n",
            "Epoch 31/100\n",
            "932/932 [==============================] - 74s 80ms/step - loss: 0.1455 - accuracy: 0.9603\n",
            "Epoch 32/100\n",
            "932/932 [==============================] - 74s 79ms/step - loss: 0.1420 - accuracy: 0.9614\n",
            "Epoch 33/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.1262 - accuracy: 0.9656\n",
            "Epoch 34/100\n",
            "932/932 [==============================] - 74s 80ms/step - loss: 0.1160 - accuracy: 0.9687\n",
            "Epoch 35/100\n",
            "932/932 [==============================] - 74s 80ms/step - loss: 0.1170 - accuracy: 0.9677\n",
            "Epoch 36/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.1075 - accuracy: 0.9699\n",
            "Epoch 37/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0997 - accuracy: 0.9726\n",
            "Epoch 38/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0975 - accuracy: 0.9725\n",
            "Epoch 39/100\n",
            "932/932 [==============================] - 74s 80ms/step - loss: 0.0927 - accuracy: 0.9743\n",
            "Epoch 40/100\n",
            "932/932 [==============================] - 74s 80ms/step - loss: 0.0884 - accuracy: 0.9760\n",
            "Epoch 41/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.1597 - accuracy: 0.9528\n",
            "Epoch 42/100\n",
            "932/932 [==============================] - 74s 79ms/step - loss: 0.0862 - accuracy: 0.9760\n",
            "Epoch 43/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0803 - accuracy: 0.9778\n",
            "Epoch 44/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0789 - accuracy: 0.9787\n",
            "Epoch 45/100\n",
            "932/932 [==============================] - 74s 80ms/step - loss: 0.0696 - accuracy: 0.9814\n",
            "Epoch 46/100\n",
            "932/932 [==============================] - 74s 80ms/step - loss: 0.1011 - accuracy: 0.9714\n",
            "Epoch 47/100\n",
            "932/932 [==============================] - 74s 80ms/step - loss: 0.0888 - accuracy: 0.9745\n",
            "Epoch 48/100\n",
            "932/932 [==============================] - 74s 79ms/step - loss: 0.0687 - accuracy: 0.9809\n",
            "Epoch 49/100\n",
            "932/932 [==============================] - 75s 81ms/step - loss: 0.0600 - accuracy: 0.9840\n",
            "Epoch 50/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0578 - accuracy: 0.9844\n",
            "Epoch 51/100\n",
            "932/932 [==============================] - 74s 80ms/step - loss: 0.0562 - accuracy: 0.9844\n",
            "Epoch 52/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0529 - accuracy: 0.9862\n",
            "Epoch 53/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0539 - accuracy: 0.9853\n",
            "Epoch 54/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0554 - accuracy: 0.9852\n",
            "Epoch 55/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.0486 - accuracy: 0.9873\n",
            "Epoch 56/100\n",
            "932/932 [==============================] - 75s 81ms/step - loss: 0.0555 - accuracy: 0.9848\n",
            "Epoch 57/100\n",
            "932/932 [==============================] - 76s 82ms/step - loss: 0.0472 - accuracy: 0.9875\n",
            "Epoch 58/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.0434 - accuracy: 0.9885\n",
            "Epoch 59/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.0437 - accuracy: 0.9883\n",
            "Epoch 60/100\n",
            "932/932 [==============================] - 77s 83ms/step - loss: 0.0482 - accuracy: 0.9866\n",
            "Epoch 61/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 1.8266 - accuracy: 0.6585\n",
            "Epoch 62/100\n",
            "932/932 [==============================] - 76s 82ms/step - loss: 0.6956 - accuracy: 0.7751\n",
            "Epoch 63/100\n",
            "932/932 [==============================] - 76s 82ms/step - loss: 0.3384 - accuracy: 0.8836\n",
            "Epoch 64/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.2430 - accuracy: 0.9169\n",
            "Epoch 65/100\n",
            "932/932 [==============================] - 76s 82ms/step - loss: 0.1965 - accuracy: 0.9355\n",
            "Epoch 66/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.1629 - accuracy: 0.9475\n",
            "Epoch 67/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.1416 - accuracy: 0.9549\n",
            "Epoch 68/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.1350 - accuracy: 0.9579\n",
            "Epoch 69/100\n",
            "932/932 [==============================] - 75s 81ms/step - loss: 0.1189 - accuracy: 0.9626\n",
            "Epoch 70/100\n",
            "932/932 [==============================] - 76s 82ms/step - loss: 0.1042 - accuracy: 0.9680\n",
            "Epoch 71/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.9430 - accuracy: 0.7589\n",
            "Epoch 72/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.2478 - accuracy: 0.9144\n",
            "Epoch 73/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.1939 - accuracy: 0.9343\n",
            "Epoch 74/100\n",
            "932/932 [==============================] - 75s 81ms/step - loss: 0.1517 - accuracy: 0.9503\n",
            "Epoch 75/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.1292 - accuracy: 0.9583\n",
            "Epoch 76/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.1177 - accuracy: 0.9625\n",
            "Epoch 77/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.1046 - accuracy: 0.9674\n",
            "Epoch 78/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.1538 - accuracy: 0.9545\n",
            "Epoch 79/100\n",
            "932/932 [==============================] - 75s 81ms/step - loss: 0.0958 - accuracy: 0.9706\n",
            "Epoch 80/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.0812 - accuracy: 0.9749\n",
            "Epoch 81/100\n",
            "932/932 [==============================] - 75s 81ms/step - loss: 0.0730 - accuracy: 0.9781\n",
            "Epoch 82/100\n",
            "932/932 [==============================] - 75s 81ms/step - loss: 0.0717 - accuracy: 0.9784\n",
            "Epoch 83/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.0665 - accuracy: 0.9798\n",
            "Epoch 84/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0638 - accuracy: 0.9807\n",
            "Epoch 85/100\n",
            "932/932 [==============================] - 75s 81ms/step - loss: 0.0615 - accuracy: 0.9810\n",
            "Epoch 86/100\n",
            "932/932 [==============================] - 75s 81ms/step - loss: 0.0605 - accuracy: 0.9812\n",
            "Epoch 87/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0541 - accuracy: 0.9832\n",
            "Epoch 88/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.0606 - accuracy: 0.9812\n",
            "Epoch 89/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0531 - accuracy: 0.9838\n",
            "Epoch 90/100\n",
            "932/932 [==============================] - 75s 81ms/step - loss: 0.0498 - accuracy: 0.9844\n",
            "Epoch 91/100\n",
            "932/932 [==============================] - 75s 81ms/step - loss: 0.0480 - accuracy: 0.9844\n",
            "Epoch 92/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0460 - accuracy: 0.9856\n",
            "Epoch 93/100\n",
            "932/932 [==============================] - 75s 81ms/step - loss: 0.0445 - accuracy: 0.9858\n",
            "Epoch 94/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0455 - accuracy: 0.9854\n",
            "Epoch 95/100\n",
            "932/932 [==============================] - 75s 80ms/step - loss: 0.0434 - accuracy: 0.9862\n",
            "Epoch 96/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.0416 - accuracy: 0.9865\n",
            "Epoch 97/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.0432 - accuracy: 0.9860\n",
            "Epoch 98/100\n",
            "932/932 [==============================] - 76s 82ms/step - loss: 0.0406 - accuracy: 0.9869\n",
            "Epoch 99/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.0404 - accuracy: 0.9867\n",
            "Epoch 100/100\n",
            "932/932 [==============================] - 76s 81ms/step - loss: 0.0397 - accuracy: 0.9872\n"
          ]
        }
      ],
      "source": [
        "sgd = SGD(learning_rate=0.001 ,momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "#fitting and saving the model\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=100, batch_size=128, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiXTxc8XNsYE",
        "outputId": "6974d4b2-d88e-41c2-d2d1-d55be208fc22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model created and saved\n"
          ]
        }
      ],
      "source": [
        "model.save( path_to_save_model+'chat_model_3', hist)\n",
        "print(\"model created and saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQWlRcZXEmuq"
      },
      "source": [
        "### **4.2.4 - Model Architecture 4**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIS8x11cEzeT",
        "outputId": "d088e33b-d89c-4935-95a9-c3f42273b025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirection  (None, 391, 256)          133120    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 391, 256)          0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 391, 128)          164352    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 391, 128)          0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 391, 128)          512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 391, 64)           41216     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 391, 64)           0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 391, 64)           256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 32)                10368     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 32)                128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense (Dense)               (None, 113)               3729      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353681 (1.35 MB)\n",
            "Trainable params: 353233 (1.35 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "932/932 [==============================] - 141s 132ms/step - loss: 4.6924 - accuracy: 0.0300\n",
            "Epoch 2/100\n",
            "932/932 [==============================] - 125s 134ms/step - loss: 4.0253 - accuracy: 0.1153\n",
            "Epoch 3/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 3.4509 - accuracy: 0.2022\n",
            "Epoch 4/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 2.9579 - accuracy: 0.2890\n",
            "Epoch 5/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 2.5412 - accuracy: 0.3532\n",
            "Epoch 6/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 2.1979 - accuracy: 0.4147\n",
            "Epoch 7/100\n",
            "932/932 [==============================] - 126s 136ms/step - loss: 1.8938 - accuracy: 0.4812\n",
            "Epoch 8/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 1.6091 - accuracy: 0.5525\n",
            "Epoch 9/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 1.3446 - accuracy: 0.6254\n",
            "Epoch 10/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 1.1106 - accuracy: 0.6866\n",
            "Epoch 11/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.9190 - accuracy: 0.7362\n",
            "Epoch 12/100\n",
            "932/932 [==============================] - 126s 136ms/step - loss: 0.7668 - accuracy: 0.7779\n",
            "Epoch 13/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.6491 - accuracy: 0.8119\n",
            "Epoch 14/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.5574 - accuracy: 0.8390\n",
            "Epoch 15/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.4864 - accuracy: 0.8608\n",
            "Epoch 16/100\n",
            "932/932 [==============================] - 126s 136ms/step - loss: 0.4312 - accuracy: 0.8749\n",
            "Epoch 17/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.3855 - accuracy: 0.8877\n",
            "Epoch 18/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.3482 - accuracy: 0.8984\n",
            "Epoch 19/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.3189 - accuracy: 0.9063\n",
            "Epoch 20/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.2918 - accuracy: 0.9139\n",
            "Epoch 21/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.2675 - accuracy: 0.9213\n",
            "Epoch 22/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.2470 - accuracy: 0.9265\n",
            "Epoch 23/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.2308 - accuracy: 0.9308\n",
            "Epoch 24/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.2167 - accuracy: 0.9358\n",
            "Epoch 25/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.2019 - accuracy: 0.9393\n",
            "Epoch 26/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1881 - accuracy: 0.9448\n",
            "Epoch 27/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1775 - accuracy: 0.9467\n",
            "Epoch 28/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1664 - accuracy: 0.9496\n",
            "Epoch 29/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1594 - accuracy: 0.9519\n",
            "Epoch 30/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1498 - accuracy: 0.9537\n",
            "Epoch 31/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1445 - accuracy: 0.9548\n",
            "Epoch 32/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1361 - accuracy: 0.9577\n",
            "Epoch 33/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1311 - accuracy: 0.9586\n",
            "Epoch 34/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1246 - accuracy: 0.9605\n",
            "Epoch 35/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1200 - accuracy: 0.9617\n",
            "Epoch 36/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1172 - accuracy: 0.9624\n",
            "Epoch 37/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1096 - accuracy: 0.9653\n",
            "Epoch 38/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1062 - accuracy: 0.9660\n",
            "Epoch 39/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.1007 - accuracy: 0.9686\n",
            "Epoch 40/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0979 - accuracy: 0.9699\n",
            "Epoch 41/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0938 - accuracy: 0.9707\n",
            "Epoch 42/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0871 - accuracy: 0.9733\n",
            "Epoch 43/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0822 - accuracy: 0.9747\n",
            "Epoch 44/100\n",
            "932/932 [==============================] - 126s 136ms/step - loss: 0.0799 - accuracy: 0.9753\n",
            "Epoch 45/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0785 - accuracy: 0.9761\n",
            "Epoch 46/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0783 - accuracy: 0.9757\n",
            "Epoch 47/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0706 - accuracy: 0.9781\n",
            "Epoch 48/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0688 - accuracy: 0.9789\n",
            "Epoch 49/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0691 - accuracy: 0.9782\n",
            "Epoch 50/100\n",
            "932/932 [==============================] - 126s 136ms/step - loss: 0.0676 - accuracy: 0.9787\n",
            "Epoch 51/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0601 - accuracy: 0.9814\n",
            "Epoch 52/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0681 - accuracy: 0.9784\n",
            "Epoch 53/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0582 - accuracy: 0.9815\n",
            "Epoch 54/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0592 - accuracy: 0.9810\n",
            "Epoch 55/100\n",
            "932/932 [==============================] - 126s 136ms/step - loss: 0.0552 - accuracy: 0.9819\n",
            "Epoch 56/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0534 - accuracy: 0.9820\n",
            "Epoch 57/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0519 - accuracy: 0.9827\n",
            "Epoch 58/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0506 - accuracy: 0.9833\n",
            "Epoch 59/100\n",
            "932/932 [==============================] - 126s 136ms/step - loss: 0.0542 - accuracy: 0.9821\n",
            "Epoch 60/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0476 - accuracy: 0.9842\n",
            "Epoch 61/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0461 - accuracy: 0.9852\n",
            "Epoch 62/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0472 - accuracy: 0.9846\n",
            "Epoch 63/100\n",
            "932/932 [==============================] - 126s 135ms/step - loss: 0.0525 - accuracy: 0.9833\n",
            "Epoch 64/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0510 - accuracy: 0.9833\n",
            "Epoch 65/100\n",
            "932/932 [==============================] - 127s 137ms/step - loss: 0.0464 - accuracy: 0.9848\n",
            "Epoch 66/100\n",
            "932/932 [==============================] - 127s 137ms/step - loss: 0.0439 - accuracy: 0.9861\n",
            "Epoch 67/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.0438 - accuracy: 0.9864\n",
            "Epoch 68/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.0454 - accuracy: 0.9846\n",
            "Epoch 69/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.0428 - accuracy: 0.9854\n",
            "Epoch 70/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.0460 - accuracy: 0.9835\n",
            "Epoch 71/100\n",
            "932/932 [==============================] - 127s 137ms/step - loss: 0.0442 - accuracy: 0.9853\n",
            "Epoch 72/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.0410 - accuracy: 0.9851\n",
            "Epoch 73/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0407 - accuracy: 0.9858\n",
            "Epoch 74/100\n",
            "932/932 [==============================] - 127s 137ms/step - loss: 0.0404 - accuracy: 0.9863\n",
            "Epoch 75/100\n",
            "932/932 [==============================] - 127s 137ms/step - loss: 0.0368 - accuracy: 0.9878\n",
            "Epoch 76/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0367 - accuracy: 0.9879\n",
            "Epoch 77/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0348 - accuracy: 0.9885\n",
            "Epoch 78/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.0339 - accuracy: 0.9886\n",
            "Epoch 79/100\n",
            "932/932 [==============================] - 127s 137ms/step - loss: 0.0333 - accuracy: 0.9891\n",
            "Epoch 80/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.0364 - accuracy: 0.9874\n",
            "Epoch 81/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0327 - accuracy: 0.9890\n",
            "Epoch 82/100\n",
            "932/932 [==============================] - 127s 137ms/step - loss: 0.0325 - accuracy: 0.9893\n",
            "Epoch 83/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.0318 - accuracy: 0.9897\n",
            "Epoch 84/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0301 - accuracy: 0.9903\n",
            "Epoch 85/100\n",
            "932/932 [==============================] - 127s 137ms/step - loss: 0.0294 - accuracy: 0.9904\n",
            "Epoch 86/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0298 - accuracy: 0.9904\n",
            "Epoch 87/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.0314 - accuracy: 0.9900\n",
            "Epoch 88/100\n",
            "932/932 [==============================] - 127s 137ms/step - loss: 0.0291 - accuracy: 0.9906\n",
            "Epoch 89/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0418 - accuracy: 0.9866\n",
            "Epoch 90/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0301 - accuracy: 0.9901\n",
            "Epoch 91/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0266 - accuracy: 0.9914\n",
            "Epoch 92/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0265 - accuracy: 0.9918\n",
            "Epoch 93/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0262 - accuracy: 0.9920\n",
            "Epoch 94/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0262 - accuracy: 0.9917\n",
            "Epoch 95/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.0258 - accuracy: 0.9917\n",
            "Epoch 96/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0256 - accuracy: 0.9916\n",
            "Epoch 97/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0292 - accuracy: 0.9907\n",
            "Epoch 98/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0275 - accuracy: 0.9914\n",
            "Epoch 99/100\n",
            "932/932 [==============================] - 127s 136ms/step - loss: 0.0256 - accuracy: 0.9918\n",
            "Epoch 100/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.0231 - accuracy: 0.9927\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(units=128,input_shape=(len(train_x[0]),1),return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(units=64,return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Bidirectional(LSTM(units=32,return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Bidirectional(LSTM(units=16,return_sequences=False)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(len(train_y[0]),activation=\"softmax\"))\n",
        "\n",
        "# Build the model\n",
        "model.build(input_shape=(None, len(train_x[0]), 1))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "sgd = SGD(learning_rate=0.001 ,momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "#fitting and saving the model\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=100, batch_size=128, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pn5pr4HjEmJ",
        "outputId": "38ff6c94-d6ef-4a1a-a890-3130ff589e47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model created and saved\n"
          ]
        }
      ],
      "source": [
        "model.save( path_to_save_model+'chat_model_4', hist)\n",
        "print(\"model created and saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X71mU4ZljETL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeHAlQgIjDpx",
        "outputId": "de9b52ff-3d23-4d8d-d62c-1e55b5094734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirection  (None, 391, 256)          133120    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 391, 256)          1024      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 391, 128)          164352    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 391, 128)          0         \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 391, 64)           41216     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 391, 64)           0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 391, 64)           256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 32)                10368     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 32)                128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense (Dense)               (None, 113)               3729      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 354193 (1.35 MB)\n",
            "Trainable params: 353489 (1.35 MB)\n",
            "Non-trainable params: 704 (2.75 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "932/932 [==============================] - 145s 137ms/step - loss: 4.6558 - accuracy: 0.0336\n",
            "Epoch 2/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 4.1301 - accuracy: 0.1049\n",
            "Epoch 3/100\n",
            "932/932 [==============================] - 128s 138ms/step - loss: 3.7473 - accuracy: 0.1478\n",
            "Epoch 4/100\n",
            "932/932 [==============================] - 128s 138ms/step - loss: 3.4378 - accuracy: 0.1868\n",
            "Epoch 5/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 3.1494 - accuracy: 0.2339\n",
            "Epoch 6/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 2.8716 - accuracy: 0.2799\n",
            "Epoch 7/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 2.6211 - accuracy: 0.3216\n",
            "Epoch 8/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 2.4007 - accuracy: 0.3596\n",
            "Epoch 9/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 2.2027 - accuracy: 0.3998\n",
            "Epoch 10/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 2.0192 - accuracy: 0.4404\n",
            "Epoch 11/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 1.8442 - accuracy: 0.4803\n",
            "Epoch 12/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 1.6993 - accuracy: 0.5156\n",
            "Epoch 13/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 1.5580 - accuracy: 0.5511\n",
            "Epoch 14/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 1.4138 - accuracy: 0.5903\n",
            "Epoch 15/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 1.2874 - accuracy: 0.6236\n",
            "Epoch 16/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 1.1761 - accuracy: 0.6543\n",
            "Epoch 17/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 1.0703 - accuracy: 0.6818\n",
            "Epoch 18/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.9511 - accuracy: 0.7191\n",
            "Epoch 19/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.9754 - accuracy: 0.7076\n",
            "Epoch 20/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.8029 - accuracy: 0.7618\n",
            "Epoch 21/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.7363 - accuracy: 0.7807\n",
            "Epoch 22/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.6862 - accuracy: 0.7938\n",
            "Epoch 23/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.6902 - accuracy: 0.7925\n",
            "Epoch 24/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.5948 - accuracy: 0.8207\n",
            "Epoch 25/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.5565 - accuracy: 0.8309\n",
            "Epoch 26/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.5487 - accuracy: 0.8341\n",
            "Epoch 27/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.5008 - accuracy: 0.8481\n",
            "Epoch 28/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.4716 - accuracy: 0.8583\n",
            "Epoch 29/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.4422 - accuracy: 0.8665\n",
            "Epoch 30/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.4298 - accuracy: 0.8706\n",
            "Epoch 31/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.6385 - accuracy: 0.8112\n",
            "Epoch 32/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.5284 - accuracy: 0.8354\n",
            "Epoch 33/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.3811 - accuracy: 0.8849\n",
            "Epoch 34/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.3357 - accuracy: 0.8987\n",
            "Epoch 35/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.3031 - accuracy: 0.9090\n",
            "Epoch 36/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.4038 - accuracy: 0.8822\n",
            "Epoch 37/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.2943 - accuracy: 0.9132\n",
            "Epoch 38/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.2569 - accuracy: 0.9228\n",
            "Epoch 39/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.5749 - accuracy: 0.8398\n",
            "Epoch 40/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.2453 - accuracy: 0.9276\n",
            "Epoch 41/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.2448 - accuracy: 0.9261\n",
            "Epoch 42/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.2230 - accuracy: 0.9331\n",
            "Epoch 43/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.2210 - accuracy: 0.9344\n",
            "Epoch 44/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.2366 - accuracy: 0.9296\n",
            "Epoch 45/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.2673 - accuracy: 0.9200\n",
            "Epoch 46/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.1893 - accuracy: 0.9443\n",
            "Epoch 47/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.2203 - accuracy: 0.9347\n",
            "Epoch 48/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.1895 - accuracy: 0.9435\n",
            "Epoch 49/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.1884 - accuracy: 0.9439\n",
            "Epoch 50/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.1903 - accuracy: 0.9426\n",
            "Epoch 51/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.1809 - accuracy: 0.9463\n",
            "Epoch 52/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.1735 - accuracy: 0.9479\n",
            "Epoch 53/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.1785 - accuracy: 0.9456\n",
            "Epoch 54/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 1.1548 - accuracy: 0.7643\n",
            "Epoch 55/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 1.3068 - accuracy: 0.6001\n",
            "Epoch 56/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 1.3468 - accuracy: 0.6587\n",
            "Epoch 57/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 2.1607 - accuracy: 0.4120\n",
            "Epoch 58/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 1.1217 - accuracy: 0.6412\n",
            "Epoch 59/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.7630 - accuracy: 0.7456\n",
            "Epoch 60/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.5916 - accuracy: 0.8025\n",
            "Epoch 61/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.5010 - accuracy: 0.8335\n",
            "Epoch 62/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.4271 - accuracy: 0.8602\n",
            "Epoch 63/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.3834 - accuracy: 0.8765\n",
            "Epoch 64/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.3504 - accuracy: 0.8858\n",
            "Epoch 65/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.3145 - accuracy: 0.8993\n",
            "Epoch 66/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.2871 - accuracy: 0.9081\n",
            "Epoch 67/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.2809 - accuracy: 0.9097\n",
            "Epoch 68/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.2499 - accuracy: 0.9205\n",
            "Epoch 69/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.2296 - accuracy: 0.9271\n",
            "Epoch 70/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.2267 - accuracy: 0.9280\n",
            "Epoch 71/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.2176 - accuracy: 0.9305\n",
            "Epoch 72/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.2333 - accuracy: 0.9261\n",
            "Epoch 73/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.2141 - accuracy: 0.9325\n",
            "Epoch 74/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.2009 - accuracy: 0.9362\n",
            "Epoch 75/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.1968 - accuracy: 0.9375\n",
            "Epoch 76/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.2325 - accuracy: 0.9285\n",
            "Epoch 77/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.1756 - accuracy: 0.9442\n",
            "Epoch 78/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.1708 - accuracy: 0.9459\n",
            "Epoch 79/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.1660 - accuracy: 0.9473\n",
            "Epoch 80/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.1923 - accuracy: 0.9391\n",
            "Epoch 81/100\n",
            "932/932 [==============================] - 129s 139ms/step - loss: 0.1514 - accuracy: 0.9520\n",
            "Epoch 82/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.1617 - accuracy: 0.9489\n",
            "Epoch 83/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.1406 - accuracy: 0.9558\n",
            "Epoch 84/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.1413 - accuracy: 0.9550\n",
            "Epoch 85/100\n",
            "932/932 [==============================] - 130s 139ms/step - loss: 0.1374 - accuracy: 0.9566\n",
            "Epoch 86/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.1682 - accuracy: 0.9468\n",
            "Epoch 87/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.1444 - accuracy: 0.9540\n",
            "Epoch 88/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.1271 - accuracy: 0.9593\n",
            "Epoch 89/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.1262 - accuracy: 0.9602\n",
            "Epoch 90/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.1205 - accuracy: 0.9622\n",
            "Epoch 91/100\n",
            "932/932 [==============================] - 128s 137ms/step - loss: 0.1179 - accuracy: 0.9625\n",
            "Epoch 92/100\n",
            "932/932 [==============================] - 128s 138ms/step - loss: 0.1276 - accuracy: 0.9594\n",
            "Epoch 93/100\n",
            "932/932 [==============================] - 128s 138ms/step - loss: 0.1176 - accuracy: 0.9630\n",
            "Epoch 94/100\n",
            "932/932 [==============================] - 128s 138ms/step - loss: 0.1193 - accuracy: 0.9627\n",
            "Epoch 95/100\n",
            "932/932 [==============================] - 128s 138ms/step - loss: 0.1077 - accuracy: 0.9659\n",
            "Epoch 96/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.1090 - accuracy: 0.9656\n",
            "Epoch 97/100\n",
            "932/932 [==============================] - 129s 138ms/step - loss: 0.1111 - accuracy: 0.9654\n",
            "Epoch 98/100\n",
            "409/932 [============>.................] - ETA: 1:11 - loss: 0.1219 - accuracy: 0.9610"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(units=128,input_shape=(len(train_x[0]),1),return_sequences=True)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Bidirectional(LSTM(units=64,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(units=32,return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Bidirectional(LSTM(units=16,return_sequences=False)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(len(train_y[0]),activation=\"softmax\"))\n",
        "\n",
        "# Build the model\n",
        "model.build(input_shape=(None, len(train_x[0]), 1))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "sgd = SGD(learning_rate=0.001 ,momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "#fitting and saving the model\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=100, batch_size=128, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVKnyKo1Ryg3"
      },
      "outputs": [],
      "source": [
        "model.save( path_to_save_model+'chat_model_5', hist)\n",
        "print(\"model created and saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gankztcp1D_a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}